{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Fraud from Enron Email\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "In 2000, Enron was one of the largest companies in the United States. By 2002, it had collapsed into bankruptcy due to widespread corporate fraud. In the resulting Federal investigation, there was a significant amount of typically confidential information entered into public record, including tens of thousands of emails and detailed financial data for top executives. \n",
    "\n",
    "In this project, I will play detective, and put my machine learning skills to use by building a person of interest identifier based on financial and email data made public as a result of the Enron scandal. \n",
    "The identifier will be build based on the provided dataset that contains several financial as well as email features for \n",
    "146 employees. 18 out of these employees are labeled as persons of interest (POI).\n",
    "The features and labels will help me build a classifier that will classify a random employee as a person of interest.\n",
    "\n",
    "\n",
    "### 2. Data Wrangling\n",
    "\n",
    "#### 2.1 Data Overview\n",
    "\n",
    "The dataset contains financial features (all units are in US dollars):\n",
    "- `salary `\n",
    "- `deferral_payments`\n",
    "- `total_payments`\n",
    "- `loan_advances`\n",
    "- `bonus`\n",
    "- `restricted_stock_deferred`\n",
    "- `deferred_income`\n",
    "- `total_stock_value`\n",
    "- `expenses`\n",
    "- `exercised_stock_options`\n",
    "- `other`\n",
    "- `long_term_incentive`\n",
    "- `restricted_stock`\n",
    "- `director_fees`\n",
    "\n",
    "Email features (units are generally number of emails messages; notable exception is ‘email_address’, which is a text string): \n",
    "- `to_messages`\n",
    "- `email_address`\n",
    "- `from_poi_to_this_person`\n",
    "- `from_messages`\n",
    "- `from_this_person_to_poi`\n",
    "- `shared_receipt_with_poi`\n",
    "\n",
    "Label (boolean, represented as integer): \n",
    "- `poi` \n",
    "\n",
    "\n",
    "The dataset is not complete. The features often do not have an entry. Here is an overview of the misssing values there are for each feature.\n",
    "\n",
    "| Feature  | Number of NaN's|\n",
    "|---|---|\n",
    "| total_stock_value|  18| \n",
    "| total_payments|  20| \n",
    "| restricted_stock|  34| \n",
    "| exercised_stock_options|  42| \n",
    "| expenses|  49| \n",
    "| salary|  49| \n",
    "| other|  52| \n",
    "| shared_receipt_with_poi|  57| \n",
    "| to_messages|  57| \n",
    "| from_poi_to_this_person|  57| \n",
    "| from_this_person_to_poi|  57| \n",
    "| from_messages|  57| \n",
    "| bonus|  62| \n",
    "| long_term_incentive|  78| \n",
    "| deferred_income|  95| \n",
    "| deferral_payments|  105| \n",
    "| restricted_stock_deferred|  126| \n",
    "| director_fees|  127| \n",
    "| loan_advances|  140| \n",
    "\n",
    "\n",
    "#### 2.2 Data removal\n",
    "\n",
    "After Exploratory Data Analysis, I found these three records that must be removed from the dataset:\n",
    "\n",
    "- `LOCKHART EUGENE E` (Contains only NaN values)\n",
    "- `TOTAL` (contains the sum for each features of each employee)\n",
    "- `THE TRAVEL AGENCY IN THE PARK` (does not represent an employee)\n",
    "\n",
    "#### 2.3 Creating new features\n",
    "\n",
    "In this part I do some additional feature engineering by constructing three new features from the ones in the raw data. I hope that these engineered features will enhance the training of the algorithm by providing information that better differentiates the patterns in the data. I expect them also to provide additional information that is not easily apparent or not clearly captures in the raw dataset. The new features are:\n",
    "\n",
    "\n",
    "- `email_from_poi_ratio`: Ratio of emails received from poi's in relation to all received emails\n",
    "- `email_to_poi_ratio`: Ratio of emails sent to poi's in relation to all sent emails\n",
    "- `total_wealth`: Sum of the `salary`, `bonus`, `exercised_stock_options`, `total_stock_value`\n",
    "\n",
    "#### 2.4 Features Scaling \n",
    "\n",
    "Feature scaling is a method used to standardize the range of features in the data. Since the range of values in the raw dataset my vary widely, some machine learning algorithms will work badly without feature scalling. The majority of classifiers calculate the distance of two points by the Euclidean distance. In the case that one of the features has a broad range of values the distance will be dominated by this feature. Because of this fact the range of all features should be scalled so that every feature in the dataset contribute proportionately to the final distance. In this project I wil use Scikit-learn's `StandardScaler()` to normalize the features. However not every classifier will use feature scaling.\n",
    "\n",
    "\n",
    "### 3. Algorithm Tuning\n",
    "\n",
    "In this project I try out several algorithms to determine which classifier provide me in the end with the best result. The used algorithms are:\n",
    "\n",
    "- Gaussian Naive Bayes\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Ada Boost \n",
    "\n",
    "Before the algorithms are used in practice I perform an algorithm tuning. The tuning involves the determination of the best input parameters to increase the algorithm´s performance.\n",
    "Algorithms have numerous input parameters that assist the decision making process during the training of an algorithm. The input parameters determine for instance which heuristics are used or the probabilities of certain events occurring.\n",
    "The performance of an algorithm is greatly affected by the parameter setting. However these setting are not easy to determine. To find out the best combination of parameter settings that provide the best performance I use Scikit-learn's `GridSearchCV()`. This function takes a classifier and a dictionary of input parameters and returns the parameters which results in the best performance of the algorithm.\n",
    "\n",
    "Here are the dictionarys of input parameters that were used by `GridSearchCV()` to determine the best parameter settings for each classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for Logistic Regression\n",
    "logReg_parameters = {\"C\":[0.5,1,5,5.5,6],\n",
    "                     \"penalty\":[\"l1\",  \"l2\"],\n",
    "                     \"tol\":[1e-2, 1e-3, 1e-4, 1e-5]\n",
    "                     } \n",
    "# Parameters for AdaBoostClassifier\n",
    "AdaBoost_parameters = {'n_estimators':[25,50,75], \n",
    "                       \"learning_rate\":[0.25, 0.5, 0.75, 1.0],\n",
    "                       } \n",
    "# Parameters for DecisionTreeClassifier\n",
    "DecisionTree_parameters = {\"criterion\":[\"gini\",\"entropy\"], \n",
    "                           \"min_samples_split\":[2,3,4],\n",
    "                           \"min_samples_leaf\":[1,2,3]\n",
    "                           } \n",
    "# Parameters for RandomForestClassifier\n",
    "RandomForest_parameters = {\"max_depth\":[3,4,5,6,7], \n",
    "                           \"criterion\":[\"gini\",\"entropy\"],\n",
    "                           \"n_estimators\":[20,25,30],\n",
    "                           \"random_state\":[35,40,45]\n",
    "                           } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of `GridSearchCV()` resulted in the following best parameter settings:\n",
    "\n",
    "##### LogisticRegression\n",
    "- C=6\n",
    "- penalty=l1\n",
    "- tol=0.001\n",
    "\n",
    "##### AdaBoostClassifier\n",
    "- n_estimators=50,\n",
    "- learning_rate=0.25\n",
    "\n",
    "##### RandomForestClassifier\n",
    "- n_estimators=20\n",
    "- criterion='entropy'\n",
    "- max_depth=3,\n",
    "- random_state=40\n",
    "\n",
    "##### DecisionTreeClassifier\n",
    "- min_samples_split=3\n",
    "- criterion='entropy'\n",
    "- min_samples_leaf=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Selection and Further Enhancement\n",
    "\n",
    "To increase the performance even more I use the Pipeline function to perform a number of operation such as `StandardScaler()`, `SelectKBest(k)` and `PCA(n_components)`. `StandardScaler()` was already mentioned. Scikit-learn's `SelectKBest(k)` is used for feature selection. The function selects features according to the `k` highest scores. Here is an overview over the features with the corresponding scores.\n",
    "\n",
    "| Feature  | Score  |\n",
    "|---|---|\n",
    "|  total_wealth | 28.26  |\n",
    "|  exercised_stock_options | 24.81  |\n",
    "|  total_stock_value | 24.18  |\n",
    "|  bonus |  20.79  |\n",
    "|  salary | 18.28  |\n",
    "|  deferred_income |  11.45 |\n",
    "| long_term_incentive  |  9.92 |\n",
    "| restricted_stock  |  9.21 |\n",
    "| total_payments  | 8.77  |\n",
    "|  shared_receipt_with_poi | 8.58  |\n",
    "|  loan_advances | 7.18  |\n",
    "|  expenses | 7.18  |\n",
    "| from_poi_to_this_person  | 5.24  |\n",
    "| email_from_poi_ratio | 5.12|\n",
    "|  other | 4.18  |\n",
    "|  email_to_poi_ratio | 4.09  |\n",
    "|  from_this_person_to_poi | 2.38  |\n",
    "|  director_fees | 2.12  |\n",
    "|  to_messages |  1.64 |\n",
    "|  deferral_payments | 0.22  |\n",
    "|  from_messages | 0.16  |\n",
    "|  restricted_stock_deferred | 0.06  |\n",
    "\n",
    "\n",
    "The new feature `tota_wealth` has the highest score, in opposite `email_from_poi_ratio` and `email_to_poi_ratio` occupy 14th and 16th place out of 22.\n",
    "\n",
    "Scikit-learn's `PCA()` is used to transform the features into Principal Components, which are used as new features. This step may increase the performance of an algorithm. The final dimension of Principal Componenets is determined by using `n_components` as input parameter for `PCA()`.\n",
    "\n",
    "\n",
    " While the set of best input parameters that were determined by `GridSearchCV()` for each algorithm stay the same I use different combinations of `StandardScaler()`, `SelectKBest()`, `PCA()` as well as combinations of `k` for `SelectKBest()` and `n_components` for `PCA()`. In the end I kept the combination of the operations and their input parameters which resulted in the best performance.\n",
    "Since I did the combinations manually I could not try out all the possible combinations there are. I am aware of the fact that some combinations I did not try out may result in even better performances.\n",
    "\n",
    "Here I provide an overview over the final manually chosen operations used in the Pipepline as well as the optimal input parameters for each algorithm determined by `GridSearchCV()` during the tuning. The expressions \"Scaler\", \"K_best\", \"PCA\" and \"clf\" correspond to `StandardScaler()`, `SelectKBest()`, `PCA()` and the used algorithm.\n",
    "'None' means that the corresponding function was not used in the pipeline. In the case of \"K_best\" it means that all features were selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pipeline(steps=[(\"Scaler\", None),\n",
    "                 (\"K_best\", None),\n",
    "                 (\"PCA\", PCA(n_components=12)),\n",
    "                 (\"clf\", LogisticRegression(C=6,\n",
    "                                            penalty=l1,\n",
    "                                            tol=0.001)\n",
    "                                            )\n",
    "               ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pipeline(steps=[(\"Scaler\", StandardScaler()),\n",
    "                (\"K_best\", None),\n",
    "                (\"PCA\", None),\n",
    "                (\"clf\", AdaBoostClassifier(n_estimators=50,\n",
    "                                           learning_rate=0.25))\n",
    "               ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pipeline(steps=[(\"Scaler\", None),\n",
    "                 (\"K_best\", SelectKBest(k=10)),\n",
    "                 (\"PCA\", PCA(n_components=5)),\n",
    "                 (\"clf\", RandomForestClassifier(n_estimators=20,\n",
    "                                                criterion='entropy',\n",
    "                                                max_depth=3,\n",
    "                                                random_state=40))\n",
    "               ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pipeline(steps=[(\"Scaler\", None),\n",
    "                 (\"K_best\", SelectKBest(k=13)),\n",
    "                 (\"PCA\", PCA(n_components=10)),\n",
    "                 (\"clf\", GaussianNB())\n",
    "               ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pipeline(steps=[(\"Scaler\", StandardScaler()),\n",
    "                 (\"K_best\", SelectKBest(k=4)),\n",
    "                 (\"PCA\", None),\n",
    "                 (\"clf\", DecisionTreeClassifier(min_samples_split=3,\n",
    "                                                criterion='entropy',\n",
    "                                                min_samples_leaf=2))\n",
    "               ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation Metrics \n",
    "\n",
    "The final part of the project is the process of checking if the algorithms fulfill their intended purpose to identify the poi's. For that reason the dataset is split into two parts: a training and a test set. The training set is used to train the algorithm to predict the poi's while the test set ist used to check the algorithm performance. It is important to use different data sets for testing and training. If test and training sets are the same we get a better but sophisticated performance, because the algorithm that try to predict an outcome for the test set had already seen the right outcome during the previous training phase.\n",
    "\n",
    "\n",
    "**Precision**, **Recall** and **F1-Score** are the used metrics to evaluate the perforamance of each algorithm. These metrics are based on:\n",
    "\n",
    "- Positive cases that were preticted correctly, True Positives (**TP**)\n",
    "- Negative cases that were preticted incorrectly, True Negatives (**TN**)\n",
    "- Positive cases that were preticted incorrectly, False Positives (**FP**)\n",
    "- Negative cases that were preticted incorrectly, False Negatives (**FN**)\n",
    "\n",
    "The metrics are calculated according to:\n",
    "\n",
    "**Precision** = **TP**/(**TP**+**FP**)\n",
    "\n",
    "**Recall** = (**TP**)/(**TP** + **FN**)\n",
    "\n",
    "**F1-Score** = (2 **Recall*Precision**)/(**Recall** + **Precision**)\n",
    "\n",
    "\n",
    "**Precision** represents the percentage of cases that the classifier labeled as positive are actually positives. Higher precision corresponds to an algorithm that tends to predict a POI correctly.\n",
    "\n",
    "**Recall** represents the percentage of positive cases that classifier labeled as positive. An algorithm with a higher precesion tends to identify a POI in the dataset.\n",
    "\n",
    "**F1-Score** represents the harmonic mean of **Recall** and **Precision**. The score takes values between 0 and 1, with 1 as the best and 0 as the worst score.\n",
    "\n",
    "To calculate the metrics I use the procedure called the cross-validation method. In this procedure the dataset is split into k smaller sets. The algorithm is trained using k-1 of these smaller sets, while the remaining set is used for the testing of the performance. This process is repeated for k times, so each subset is used for the validation exactly one time.\n",
    "The method allows doing evalution of an algorithm that uses a very small dataset, that happens to be the case in this project. The cross-validation method is implemented in the function `test_classifier()`.  \n",
    "Furthermore I am dealing with the problem that the used dataset is very imbalanced. The number of non POIs is much higher than the number of POIs.\n",
    "Splitting the dataset into training and test subsets may result in the fact that all POIs are allocated to the training set. In that case it wouldn't be possible to check if the classifier is actually good in predicting POIs. Ideally the training and test set should have the same ratio between POIs and non-POIs, this is called stratification. To achieve this `test_classifier()` contains the Scikit-learn's function `StratifiedShuffleSplit()` which performs the stratification.\n",
    "\n",
    "\n",
    "The resulsting **Precision**, **Recall** and **F1-Score** for each algorithm are given below.\n",
    "\n",
    "    \n",
    "\n",
    "| Algorithm  | Precision  | Recall |   F1-Score |\n",
    "|------------|------------|--------|------------|\n",
    "|  Gaussian Naive Bayes |  0.451  |0.372 | 0.408\n",
    "|  Ada Boost |  0.332  | 0.269 | 0.297\n",
    "|  Logistic Regression|  0.407 | 0.229|  0.293\n",
    "|  Decision Tree |  0.298  | 0.237|   0.264\n",
    "|  Random Forest |   0.535  | 0.168| 0.255\n",
    "\n",
    "\n",
    "Using **F1-Score** as the main metric for the evaluation the Gaussian Naive Bayes tends to be the best algorithm.\n",
    "45,1% of predicted persons of interest were the actual POI's while 37,2 % of POI's in the dataset were found.\n",
    "In comparison Random Forest algorithm predicted 53,5% of the POI's correctly while only 16,8% of POI's in the dataset were found. \n",
    "\n",
    "\n",
    "The performance of Gaussian Naive Bayes was achieved by selecting 13 features with best scores and picking 10 Principal Components. Using only the best 13 features means that the new features `email_from_poi_ratio` and `email_to_poi_ratio`  have no impact on the performance on the algorithm. In comparison `total_wealth` do have a massive influence on the performance. Removing this feature from the feature list I get the following values for the metrics:\n",
    "- **Precision**: 0.335     \n",
    "- **Recall**: 0.329\n",
    "- **F1**: 0.332\n",
    "\n",
    "Using `StandardScaler()` lowered the performance also. That leads to the assumption that Gaussian Naive Bayes do not need any normalization to work properly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
